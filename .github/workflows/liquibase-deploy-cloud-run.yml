name: Liquibase PoC via Cloud Run Job (self-healing)

on:
  workflow_dispatch:
  push:
    branches: [ main ]

permissions:
  contents: read

env:
  GCP_PROJECT: autodeploydb
  GCP_REGION: us-central1
  JOB_NAME: liquibase-apply

  # Adjust these to your DB/user
  INSTANCE_URI: projects/autodeploydb/locations/us-central1/clusters/alloydb-cluster/instances/alloydb-primary
  DB_NAME: test_liquibase
  DB_USER: postgres

  # VPC connector (must already exist in us-central1)
  VPC_CONNECTOR: projects/autodeploydb/locations/us-central1/connectors/cr-liquibase-connector

  # Runtime service account for the Job (created by your one-time script)
  RUN_SA_EMAIL: cloud-run-liquibase@autodeploydb.iam.gserviceaccount.com

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Authenticate to GCP (JSON key)
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Install gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.GCP_PROJECT }}

      - name: Show active account and project
        run: |
          gcloud auth list
          gcloud config set project "${{ env.GCP_PROJECT }}"
          gcloud config set run/region "${{ env.GCP_REGION }}"

      - name: Ensure Cloud Run Job exists (deploy from source if missing)
        id: ensure
        shell: bash
        run: |
          set -euo pipefail
          if gcloud run jobs describe "${JOB_NAME}" --region "${GCP_REGION}" >/dev/null 2>&1; then
            echo "exists=true" >> "$GITHUB_OUTPUT"
            echo "Job ${JOB_NAME} already exists."
          else
            echo "exists=false" >> "$GITHUB_OUTPUT"
            echo "Job ${JOB_NAME} not found. Deploying from source..."
            # This uses buildpacks (no Dockerfile)
            gcloud run jobs deploy "${JOB_NAME}" \
              --source . \
              --region "${GCP_REGION}" \
              --service-account "${RUN_SA_EMAIL}" \
              --vpc-connector "${VPC_CONNECTOR}" \
              --vpc-egress all-traffic
          fi

      # Update env vars with DB creds (requires roles/run.admin)
      - name: Update Job env vars (INSTANCE_URI, DB_NAME/USER, DB_PASSWORD)
        run: |
          gcloud run jobs update "${JOB_NAME}" \
            --region "${{ env.GCP_REGION }}" \
            --update-env-vars "INSTANCE_URI=${{ env.INSTANCE_URI }},DB_NAME=${{ env.DB_NAME }},DB_USER=${{ env.DB_USER }},DB_PASSWORD=${{ secrets.ALLOYDB_PASSWORD }}"

      - name: Execute Cloud Run Job
        run: |
          gcloud run jobs execute "${JOB_NAME}" \
            --region "${{ env.GCP_REGION }}" \
            --wait

      # Optional: remove DB_PASSWORD from saved config after the run
      - name: Scrub DB_PASSWORD from Job config (optional)
        if: always()
        run: |
          gcloud run jobs update "${JOB_NAME}" \
            --region "${{ env.GCP_REGION }}" \
            --remove-env-vars "DB_PASSWORD"

      - name: Show latest Job execution logs
        run: |
          EXEC_ID=$(gcloud run jobs executions list \
            --job="${JOB_NAME}" \
            --region "${{ env.GCP_REGION }}" \
            --format="value(name)" \
            --limit=1)
          echo "Execution: $EXEC_ID"
          gcloud run jobs executions logs read "$EXEC_ID" \
            --region "${{ env.GCP_REGION }}" \
            --limit=200
